# Libraries
import streamlit as st
from pydub import AudioSegment
import openai
from datetime import timedelta
import os
import re
from function import check_password

# Confit
st.set_page_config(page_title='PEACE', page_icon=':earth_asia:', layout='wide')

# Title
st.title('ğŸ¥¦ Whisper')

# Style
with open('style.css')as f:
    st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html = True)

#-------------------------------------------------------------------------------#

# Load Chatgpt API key
os.environ['OPENAI_API_KEY'] = st.secrets["chatgpt_api"]

# Check password
if check_password():

    # Upload audio
    uploaded_audio = st.file_uploader("", type=['mp3', 'mp4', 'mpeg', 'mpga', 'm4a', 'wav', 'webm'])


    if uploaded_audio:
        # Finde audio extension
        extension = str(uploaded_audio.name)[re.search(r'\w*.\w$', str(uploaded_audio.name)).start():]

        # è®€å–ä¸‹è¼‰ä¸‹ä¾†çš„éŸ³æª”
        audio_file = AudioSegment.from_file(uploaded_audio)

        with st.spinner(f'Cut into chunk...'):
            # åˆ‡å‰²éŸ³æª”æˆå¤šå€‹å°æª”æ¡ˆ
            chunk_size = 40 * 60 * 1000  # 40åˆ†é˜
            chunks = [audio_file[i:i+chunk_size] for i in range(0, len(audio_file), chunk_size)]

        with st.spinner(f'Speech to text...'):
            # ä½¿ç”¨ OpenAI çš„ Audio API å°‡æ¯å€‹å°æª”æ¡ˆè½‰æˆæ–‡å­—ï¼Œç„¶å¾Œåˆä½µåœ¨ä¸€èµ·
            transcript = ""
            for chunk in chunks:
                with chunk.export(f"temp.mp3", format='mp3') as f:
                    result = openai.Audio.transcribe("whisper-1", f)
                    transcript += result["text"]

        # ä¾ç…§æˆ‘å€‘æŒ‡å®šçš„é•·åº¦åˆ†å‰²å­—ä¸²
        def split_text(text, max_length):
            return [text[i:i+max_length] for i in range(0, len(text), max_length)]

        # ä¾ç…§ type è™•ç†æ–‡å­—
        def process_text(text, type):
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": type + text}
                ]
            )
            return response.choices[0].message.content

        # è™•ç†é•·å­—ä¸²
        def process_long_text(long_text, type):
            text_list = split_text(long_text, 1200)
            processed_text_list = [process_text(text, type) for text in text_list]
            return "".join(processed_text_list)


        with st.spinner(f'Get comprehensive content...'):
            # å‘¼å«åˆ†æ®µè™•ç†å‡½å¼
            processed_transcript = process_long_text(transcript, "ä½¿ç”¨ç¹é«”ä¸­æ–‡é–±è®€ï¼Œå¹«æˆ‘æ”¹éŒ¯å­—ã€åŠ æ¨™é»ç¬¦è™Ÿï¼Œä¸¦åˆ†æ®µä½¿å…§å®¹æ›´é€šé †ï¼š\n")

        with st.spinner(f'Get summarized content...'):
            # å‘¼å«å–å¾—æ‘˜è¦å‡½å¼
            processed_summary = process_long_text(processed_transcript, "é–±è®€ä»¥ä¸‹æ–‡å­—ï¼Œç”¨ã€Œ-ã€ä½œç‚ºå‰ç¶´æ¢åˆ—å‡ºé‡é»ï¼Œç”¨ã€Œç¹é«”ä¸­æ–‡ã€å‘ˆç¾ï¼š\n")


        st.subheader('Context:')
        st.write(processed_transcript)

        st.write('---')

        st.subheader('Summary:')
        st.write(processed_summary)


        # Store Context + Summary
        with open(os.path.join('history_audio_paragraph', f'{uploaded_audio.name}.txt'), 'w') as f:
            f.write(processed_transcript)
        with open(os.path.join('history_audio_summary', f'{uploaded_audio.name}.txt'), 'w') as f:
            f.write(processed_summary)



        # Statictics
        duration = str(timedelta(seconds=len(audio_file)/1000)).split(':')

        st.caption('Time: {} hour  {} min  {} sec'.format(duration[0], duration[1], duration[2]))
        st.caption(f'Price: ${0.006*(len(audio_file)/1000/60)}')


